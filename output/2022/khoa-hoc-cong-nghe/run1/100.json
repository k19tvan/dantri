{
    "url": "https://dantri.com.vn/khoa-hoc-cong-nghe/mat-toi-cua-ai-robot-nay-da-biet-phan-biet-gioi-tinh-va-chung-toc-20220628061142942.htm",
    "title": "Mặt tối của AI: Robot nay đã biết phân biệt giới tính và chủng tộc",
    "content": "Mặt tối của AI: Robot nay đã biết phân biệt giới tính và chủng tộc\nMinh Khôi\nThứ ba, 28/06/2022 - 06:59\n(Dân trí) - Những lo ngại về hiểm họa mà trí tuệ nhân tạo có thể đặt ra trong tương lai, đang dần hiện hữu.\nTrí tuệ nhân tạo đang cho thấy những \"suy nghĩ\" được hình thành theo hướng tiêu cực (Ảnh minh họa).\nTrong nhiều năm, các nhà khoa học đã cảnh báo về những hiểm họa mà trí tuệ nhân tạo (AI) đặt ra trong tương lai - không chỉ ở khía cạnh máy móc lật đổ loài người, mà còn theo những cách phức tạp hơn.\nGần đây, các nhà nghiên cứu từ Viện Công nghệ Georgia (Mỹ) đã phát hiện ra rằng AI có thể tạo ra những thành kiến có hại, dẫn đến những kết luận phân biệt giới tính và phân biệt chủng tộc được hình thành từ trong \"suy nghĩ\" của chúng.\nĐiều này được chúng thể hiện một cách tự chủ, không phải là ngẫu nhiên, mà định hình từ những thành kiến có thể dễ dàng diễn ra trong thế giới thực với một người bình thường.\nĐể chứng minh điều này, các nhà nghiên cứu đã sử dụng một mạng nơ-ron gọi là CLIP, với mô hình kết hợp hình ảnh với văn bản dựa trên một tập dữ liệu lớn về các hình ảnh có chú thích trên Internet, sau đó tích hợp với một hệ thống robot có tên là Baseline.\nRobot sau đó sẽ điều khiển các cánh tay để thao tác với các đối tượng trong môi trường mô phỏng. Trong trường hợp cụ thể này, robot được yêu cầu đặt các vật thể hình khối vào một chiếc hộp tương ứng với hình ảnh hiển thị khuôn mặt của một người - có thể là cả nam và nữ, thuộc về những chủng tộc khác nhau.\nCác nhà nghiên cứu lo ngại rằng những nhận định thiếu khách quan của robot có thể sẽ khiến con người chịu hậu quả (Ảnh minh họa).\nTrong một viễn cảnh lý tưởng, cả con người và máy móc đều sẽ không bao giờ phát triển những suy nghĩ \"vô căn cứ\" và mang tính thành kiến dựa trên dữ liệu thiếu sót hoặc không đầy đủ. Tuy nhiên không may mắn rằng, không chỉ con người mà giờ đây cả robot đều mắc phải những sai sót này.\nCụ thể, khi được yêu cầu chọn \"khối tội phạm\", robot sẽ có xu hướng chọn khối có khuôn mặt của người da đen nhiều hơn khoảng 10%. Với yêu cầu chọn \"khối người gác cổng\", robot cũng có xu hướng chọn các đối tượng có gốc Mỹ Latinh nhiều hơn khoảng 10%. Đáng chú ý, phụ nữ thuộc mọi sắc tộc luôn được chọn ít hơn ở gần như mọi hạng mục, cho thấy sự phân biệt giới tính và chủng tộc được thể hiện khá rõ rệt trong những lựa chọn của robot.\n\"Chúng ta có nguy cơ tạo ra một thế hệ robot phân biệt chủng tộc và giới tính, nhưng điều đáng lo ngại là mọi người và các tổ chức đã quyết định vẫn tiếp tục tạo ra những sản phẩm thế này mà không đi vào giải quyết các vấn đề\", Andrew Hundt, tác giả chính của nghiên cứu cho hay.\nMặc dù thí nghiệm trên có thể chỉ diễn ra trong một kịch bản ảo, nhưng trong tương lai, mọi thứ có thể trở nên rất khác và gây ra những hậu quả nghiêm trọng.\nCác nhà nghiên cứu bày tỏ sự lo ngại của mình thông qua thí dụ về một robot an ninh. Họ cho rằng nếu như được trao quyền, robot có thể quan sát và khuếch đại các thành kiến \"xấu\" trong khi tiến hành công việc, từ đó dẫn tới những nhận định sai lầm.\nTheo họ, phương án lý tưởng nhất là nên lập trình robot để chúng từ chối đưa ra bất kỳ dự đoán nào nếu như thông tin không có sẵn hoặc không phù hợp.\nTheo\nwww.sciencealert.com",
    "metadata": [
        [
            "https://cdnphoto.dantri.com.vn/4vmQegQM_xA4QRy7eED_RJ2lfC8=/thumb_w/1020/2022/06/28/robot-3-1656371299357.jpg",
            "Trí tuệ nhân tạo đang cho thấy những \"suy nghĩ\" được hình thành theo hướng tiêu cực (Ảnh minh họa)."
        ],
        [
            "https://cdnphoto.dantri.com.vn/uaHiWW-2kRm_j1FKlTMxYh4kO60=/thumb_w/1020/2022/06/28/robot-lifestlye-060122-1656371392426.jpg",
            "Các nhà nghiên cứu lo ngại rằng những nhận định thiếu khách quan của robot có thể sẽ khiến con người chịu hậu quả (Ảnh minh họa)."
        ]
    ]
}